{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "028b44b4c521d6d685d542f4dcd8c6ead4d52a29"
   },
   "source": [
    "# Coreference resolution with fast.ai\n",
    "\n",
    "In this notebook, we will explore ULMFiT approach to solve this task. With proper fine-tuning, you can get decent results in a matter of 20 minutes. Some 15 epochs of fine-tuning will get you up to 20-ish place.\n",
    "\n",
    "Changes in this version:\n",
    "1. More civilized approach to validation.\n",
    "2. The model uses the representation of the last token of the entity instead of the first token. With a unidirectional encoder, this might be the right thing to do.\n",
    "\n",
    "I will be grateful for any suggestions, especially about converting two logits/probabilities into the three classes without the need for an additional layer.\n",
    "\n",
    "## Collect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "2ec42552a08892a35e7787748ea516b7e58b9edb"
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/google-research-datasets/gap-coreference/raw/master/gap-development.tsv -q\n",
    "!wget https://github.com/google-research-datasets/gap-coreference/raw/master/gap-test.tsv -q\n",
    "!wget https://github.com/google-research-datasets/gap-coreference/raw/master/gap-validation.tsv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "data_path = Path(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "790674e9f572c4d6a0a19081789b7b0b8ae1f7d6"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(data_path/\"gap-development.tsv\", sep=\"\\t\")\n",
    "val = pd.read_csv(data_path/\"gap-validation.tsv\", sep=\"\\t\")\n",
    "test = pd.read_csv(data_path/\"gap-test.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "bd8fc631370646784dfa9757a98b682b2d9adba1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 454 2000\n"
     ]
    }
   ],
   "source": [
    "print(len(train), len(val), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "f351e845ab84a4f29a84e4f65929b1975bbd6792"
   },
   "outputs": [],
   "source": [
    "train[\"is_valid\"] = True\n",
    "test[\"is_valid\"] = False\n",
    "val[\"is_valid\"] = True\n",
    "\n",
    "df_pretrain = pd.concat([train, test, val])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "eaa64857d482fbed4ea996f3a8520232996b5f83"
   },
   "source": [
    "Finetune the language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "c6f54e378d0cfec8dab4935f7430e7c14c0ca8ac"
   },
   "outputs": [],
   "source": [
    "db = (TextList.from_df(df_pretrain, data_path/\"db\", cols=\"Text\").split_from_df(col=\"is_valid\").label_for_lm().databunch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "f5d9ab1b82a244555c46f280761c9120298caec0"
   },
   "outputs": [],
   "source": [
    "vocab = db.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "7b2434521b7e3287c8c6dad959787ed6f545291f"
   },
   "outputs": [],
   "source": [
    "lm = language_model_learner(db, AWD_LSTM, drop_mult=0.5, pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "030bac492091e483046405266580ca15718ad1a2"
   },
   "source": [
    "As the language model is already trained on Wikipedia, which is also the source of the excerpts, we can proceed to unfreezing right away:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "0e4111993ec671d09463c1531037746dd0e22c14"
   },
   "outputs": [],
   "source": [
    "lm.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "745f53ab2a6edbd3b565d6c6a3ace9c634d053a9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "lm.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "0fae9307da8420efd51ec7480fe66ffd6fc0961f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min numerical gradient: 1.32E-02\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "fcfedad52f103c9b0d60ce48a2216bd634f689cd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 01:23 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>3.710937</th>\n",
       "    <th>3.170925</th>\n",
       "    <th>0.397909</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>3.514193</th>\n",
       "    <th>3.117543</th>\n",
       "    <th>0.405420</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>3.374866</th>\n",
       "    <th>3.105239</th>\n",
       "    <th>0.406485</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm.fit_one_cycle(3, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "6329d4fce060e4df1f7e9af68ad78842b7087fb8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 01:24 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>3.266881</th>\n",
       "    <th>3.098669</th>\n",
       "    <th>0.407237</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>3.194964</th>\n",
       "    <th>3.089522</th>\n",
       "    <th>0.406755</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>3.084027</th>\n",
       "    <th>3.086254</th>\n",
       "    <th>0.406391</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm.fit_one_cycle(3, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aff2f217a1b6916001afca23ff6d47ad7eeaf06a"
   },
   "source": [
    "## Preprocess the dataset for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "a227caf12041d58b50609836d587e03ef8037ce5"
   },
   "outputs": [],
   "source": [
    "spacy_tok = SpacyTokenizer(\"en\")\n",
    "tokenizer = Tokenizer(spacy_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "e5f5eaf2e467ae9889a7c319286f5e7a2d136bcd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4454.000000\n",
       "mean      102.299731\n",
       "std        30.172871\n",
       "min        16.000000\n",
       "25%        82.000000\n",
       "50%        98.000000\n",
       "75%       117.000000\n",
       "max       342.000000\n",
       "Name: Text, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pretrain.Text.apply(lambda x: len(tokenizer.process_text(x, spacy_tok))).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d9f84eca4aff61bc042b61d61c79b8a31227f2f1"
   },
   "source": [
    "Note that for simplicity we only use the first token of the entity, this is a point that can be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "863a7c384d8e040ee657cccdc5b76bbcc52f6f40"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "def get_token_num_by_offset(s, offset):\n",
    "  s_pre = s[:offset]\n",
    "  return len(spacy_tok.tokenizer(s_pre))\n",
    "\n",
    "# note that 'xxunk' is not special in this sense\n",
    "special_tokens = ['xxbos','xxfld','xxpad', 'xxmaj','xxup','xxrep','xxwrep']\n",
    "\n",
    "\n",
    "def adjust_token_num(processed, token_num):\n",
    "  \"\"\"\n",
    "  As fastai tokenizer introduces additional tokens, we need to adjust for them.\n",
    "  \"\"\"\n",
    "  counter = -1\n",
    "  do_unrep = None\n",
    "  for i, token in enumerate(processed):\n",
    "    if token not in special_tokens:\n",
    "      counter += 1\n",
    "    if do_unrep:\n",
    "      do_unrep = False\n",
    "      if processed[i+1] != \".\":\n",
    "        token_num -= (int(token) - 2) # one to account for the num itself\n",
    "      else:  # spacy doesn't split full stops\n",
    "        token_num += 1\n",
    "    if token == \"xxrep\":\n",
    "      do_unrep = True\n",
    "    if counter == token_num:\n",
    "      return i\n",
    "  else:\n",
    "    counter = -1\n",
    "    for i, t in enumerate(processed):\n",
    "      if t not in special_tokens:\n",
    "        counter += 1\n",
    "      print(i, counter, t)\n",
    "    raise Exception(f\"{token_num} is out of bounds ({processed})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "473cd798c91c157957a5c37b2f5c8b5322a0e0ed"
   },
   "outputs": [],
   "source": [
    "def dataframe_to_tensors(df, max_len=512):\n",
    "  # offsets are: pron_tok_offset, a_tok_offset, a_tok_right_offset, b_tok_offset, b_tok_right_offset\n",
    "  offsets = list()\n",
    "  labels = np.zeros((len(df),), dtype=np.int64)\n",
    "  processed = list()\n",
    "  for i, row in tqdm(df.iterrows()):\n",
    "    try:\n",
    "      text = row[\"Text\"]\n",
    "      a_offset = row[\"A-offset\"]\n",
    "      a_len = len(nlp(row[\"A\"]))\n",
    "      \n",
    "      b_offset = row[\"B-offset\"]\n",
    "      b_len = len(nlp(row[\"B\"]))\n",
    "\n",
    "      pron_offset = row[\"Pronoun-offset\"]\n",
    "      is_a = row[\"A-coref\"]\n",
    "      is_b = row[\"B-coref\"]\n",
    "      a_tok_offset = get_token_num_by_offset(text, a_offset)\n",
    "      b_tok_offset = get_token_num_by_offset(text, b_offset)\n",
    "      a_right_offset = a_tok_offset + a_len - 1\n",
    "      b_right_offset = b_tok_offset + b_len - 1\n",
    "      pron_tok_offset = get_token_num_by_offset(text, pron_offset)\n",
    "      tokenized = tokenizer.process_text(text, spacy_tok)[:max_len]\n",
    "      tokenized = [\"xxpad\"] * (max_len - len(tokenized)) + tokenized  # add padding\n",
    "      a_tok_offset = adjust_token_num(tokenized, a_tok_offset)\n",
    "      a_tok_right_offset = adjust_token_num(tokenized, a_right_offset)\n",
    "      b_tok_offset = adjust_token_num(tokenized, b_tok_offset)\n",
    "      b_tok_right_offset = adjust_token_num(tokenized, b_right_offset)\n",
    "      pron_tok_offset = adjust_token_num(tokenized, pron_tok_offset)\n",
    "      numericalized = vocab.numericalize(tokenized)\n",
    "      processed.append(torch.tensor(numericalized, dtype=torch.long))\n",
    "      offsets.append([pron_tok_offset, a_tok_offset, a_tok_right_offset, b_tok_offset, b_tok_right_offset])\n",
    "      if is_a:\n",
    "        labels[i] = 0\n",
    "      elif is_b:\n",
    "        labels[i] = 1\n",
    "      else:\n",
    "        labels[i] = 2\n",
    "    except Exception as e:\n",
    "      print(i)\n",
    "      raise\n",
    "  processed = torch.stack(processed)\n",
    "  offsets = torch.tensor(offsets, dtype=torch.long)\n",
    "  labels = torch.from_numpy(labels)\n",
    "  return processed, offsets, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "45594da37e683be4ed7b3b393b18d26d841bc5ce",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14842754382f4159a3616043bad7b543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de709b908d3a49f696677fcebeee171e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865ee01a03454cedaf0b1d27f877d497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_ds = TensorDataset(*dataframe_to_tensors(test))\n",
    "valid_ds = TensorDataset(*dataframe_to_tensors(val))\n",
    "test_ds = TensorDataset(*dataframe_to_tensors(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "f22f6b99aecc792e4b97ec8f24749ce60ce96e8e"
   },
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=32, shuffle=False)\n",
    "test_dl = DataLoader(test_ds, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a95fefd9bfe6357249382a25d58860be14efdf12"
   },
   "source": [
    "## Classifier architecture \n",
    "\n",
    "Unfortunately, the magic of fast.ai stops here: we need to create a custom classifier on top. What we do here is:\n",
    "1. Extract hidden states corresponding to entities and the pronoun.\n",
    "2. For each pair (pronoun, entity) we run it through a hidden layer to retrieve a 25-dimensional vector that describes their similarity.\n",
    "3. Concat the vectors.\n",
    "4. Use another layer to turn these into probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "6711e79b78313bc49a3ca3162c39595749898aeb"
   },
   "outputs": [],
   "source": [
    "lm.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "fe723133069de9b5a074328094564b5267e4ddbd"
   },
   "outputs": [],
   "source": [
    "encoder_hidden_sz = 400\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "class CorefResolver(nn.Module):\n",
    "  def __init__(self, encoder, dropout_p=0.3):\n",
    "    super(CorefResolver, self).__init__()\n",
    "    self.encoder = encoder\n",
    "    self.dropout = nn.Dropout(dropout_p)\n",
    "    self.hidden2hidden = nn.Linear(encoder_hidden_sz * 2 + 1, 25)\n",
    "    self.hidden2logits = nn.Linear(50, 3)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.activation = nn.LogSoftmax(dim=1)\n",
    "    self.loss = nn.NLLLoss()\n",
    "    \n",
    "  def forward(self, seqs, offsets, labels=None):\n",
    "    encoded = self.dropout(self.encoder(seqs)[0][2])\n",
    "    a_q = list()\n",
    "    b_q = list()\n",
    "    for enc, offs in zip(encoded, offsets):\n",
    "      # extract the hidden states that correspond to A, B and the pronoun, and make pairs of those \n",
    "      a_repr = enc[offs[2]]\n",
    "      b_repr = enc[offs[4]]\n",
    "      a_q.append(torch.cat([enc[offs[0]], a_repr, torch.dot(enc[offs[0]], a_repr).unsqueeze(0)]))\n",
    "      b_q.append(torch.cat([enc[offs[0]], b_repr, torch.dot(enc[offs[0]], b_repr).unsqueeze(0)]))\n",
    "    a_q = torch.stack(a_q)\n",
    "    b_q = torch.stack(b_q)\n",
    "    # apply the same \"detector\" layer to both batches of pairs\n",
    "    is_a = self.relu(self.dropout(self.hidden2hidden(a_q)))\n",
    "    is_b = self.relu(self.dropout(self.hidden2hidden(b_q)))\n",
    "    # concatenate outputs of the \"detector\" layer to get the final probability distribution\n",
    "    is_a_b = torch.cat([is_a, is_b], dim=1)\n",
    "    is_logits = self.hidden2logits(self.dropout(self.relu(is_a_b)))\n",
    "\n",
    "    activation = self.activation(is_logits)\n",
    "    if labels is not None:\n",
    "      return activation, self.loss(activation, labels)\n",
    "    else:\n",
    "      return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "3b7042607f3de0ecb4ccf8a79672be8a72c3b154"
   },
   "outputs": [],
   "source": [
    "enc = lm.model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "642af6e86490d426ee5b156d173d1f2a604ce090"
   },
   "outputs": [],
   "source": [
    "resolver = CorefResolver(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "5d4211f4d9482434006c1fe886192197f2033445"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CorefResolver(\n",
       "  (encoder): AWD_LSTM(\n",
       "    (encoder): Embedding(6590, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(6590, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1150, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1150, 1150, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1150, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3)\n",
       "  (hidden2hidden): Linear(in_features=801, out_features=25, bias=True)\n",
       "  (hidden2logits): Linear(in_features=50, out_features=3, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (activation): LogSoftmax()\n",
       "  (loss): NLLLoss()\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resolver.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "982f65b2377e3d104d3144cb7a7e2cb0b63f3f28"
   },
   "outputs": [],
   "source": [
    "for param in resolver.encoder.parameters():\n",
    "  param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "380024dd598e9e4f759cfa84ee4215232cfa5d40"
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(resolver.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "974af0cbdb7026476bfcc6467924ea3af6166158"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "754a613a4a251c6add0ce425a1497cd2997bc4d9"
   },
   "source": [
    "## Define the training loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "7b680e7f3c3ec3695ec95320777585017adc5352"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, train_dl, report_every=10):\n",
    "  model.train()\n",
    "  step = 0\n",
    "  total_loss = 0\n",
    "  \n",
    "  for texts, offsets, labels in train_dl:\n",
    "    texts, offsets, labels = texts.to(device), offsets.to(device), labels.to(device)\n",
    "    step += 1\n",
    "    optimizer.zero_grad()\n",
    "    _, loss = model(texts, offsets, labels)\n",
    "    total_loss += loss.item()\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % report_every == 0:\n",
    "      print(f\"Step {step}, loss: {total_loss/report_every}\")\n",
    "      total_loss = 0\n",
    "      \n",
    "def evaluate(model, optimizer, valid_dl, probas=False):\n",
    "  probas = list()\n",
    "  model.eval()\n",
    "  predictions = list()\n",
    "  total_loss = 0\n",
    "  all_labels = list()\n",
    "  with torch.no_grad():\n",
    "    for texts, offsets, labels in valid_dl:\n",
    "      texts, offsets, labels = texts.cuda(), offsets.cuda(), labels.cuda()\n",
    "      preds, loss = model(texts, offsets, labels)\n",
    "      total_loss += loss.item()\n",
    "      probas.append(preds.cpu().detach().numpy())\n",
    "      predictions.extend([i.item() for i in preds.max(1)[1]])\n",
    "    \n",
    "    \n",
    "  print(f\"Validation loss: {total_loss/len(valid_dl)}\")\n",
    "  print()\n",
    "  print(classification_report(valid_dl.dataset.tensors[2].numpy(), predictions))\n",
    "  if probas:\n",
    "    return total_loss, np.vstack(probas)\n",
    "  return total_loss, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a6b2952ec137595b9545ed220f87e2172ce21839"
   },
   "source": [
    "## Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "2a97960f3c98af31acf7500f226103ef930595f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Step 10, loss: 1.050875961780548\n",
      "Step 20, loss: 0.9871823012828826\n",
      "Step 30, loss: 0.9225421845912933\n",
      "Validation loss: 0.9452668905258179\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.75      0.63       187\n",
      "           1       0.62      0.59      0.60       205\n",
      "           2       0.00      0.00      0.00        62\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       454\n",
      "   macro avg       0.39      0.45      0.41       454\n",
      "weighted avg       0.50      0.57      0.53       454\n",
      "\n",
      "Loss improved, saving 1\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10, loss: 0.9050243198871613\n",
      "Step 20, loss: 0.874844080209732\n",
      "Step 30, loss: 0.842612361907959\n",
      "Validation loss: 0.8807935953140259\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.69      0.66       187\n",
      "           1       0.61      0.75      0.67       205\n",
      "           2       0.00      0.00      0.00        62\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       454\n",
      "   macro avg       0.42      0.48      0.45       454\n",
      "weighted avg       0.54      0.62      0.58       454\n",
      "\n",
      "Loss improved, saving 2\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10, loss: 0.8336462378501892\n",
      "Step 20, loss: 0.8041193425655365\n",
      "Step 30, loss: 0.8216144621372223\n",
      "Validation loss: 0.8497530778249105\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.78      0.67       187\n",
      "           1       0.66      0.67      0.67       205\n",
      "           2       0.00      0.00      0.00        62\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       454\n",
      "   macro avg       0.42      0.48      0.45       454\n",
      "weighted avg       0.54      0.63      0.58       454\n",
      "\n",
      "Loss improved, saving 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "total_epoch = 0\n",
    "best_loss = 1e6\n",
    "\n",
    "for i in range(3):\n",
    "  print(\"Epoch\", i + 1)\n",
    "  total_epoch += 1\n",
    "  train_epoch(resolver, optimizer, train_dl) \n",
    "  loss, labels = evaluate(resolver, optimizer, valid_dl)\n",
    "  if loss < best_loss:\n",
    "    best_loss = loss\n",
    "    print(f\"Loss improved, saving {total_epoch}\")\n",
    "    torch.save(resolver.state_dict(), data_path/\"model_best.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2f990cf42a93c5ada5c8ce8743e0eb0254b79f03"
   },
   "source": [
    "Unfreeze the encoder and do fine-tuning. We do the finetuning until the model starts to recognize class `2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "df37aa35a62c3117b82f1c507b10ded67deaba9e"
   },
   "outputs": [],
   "source": [
    "for param in resolver.encoder.parameters():\n",
    "  param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "cc0f1871538a13a24baac31a0d56df182e391c2b"
   },
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "optimizer = torch.optim.Adam(resolver.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "320c0a45dd83cdf426f2e4d25663ed94aa83ce16",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Step 10, loss: 0.7450408041477203\n",
      "Step 20, loss: 0.7687078475952148\n",
      "Step 30, loss: 0.785717111825943\n",
      "Validation loss: 0.8158687949180603\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.74      0.68       187\n",
      "           1       0.65      0.74      0.69       205\n",
      "           2       0.00      0.00      0.00        62\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       454\n",
      "   macro avg       0.42      0.49      0.46       454\n",
      "weighted avg       0.55      0.64      0.59       454\n",
      "\n",
      "Loss improved, saving 4\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10, loss: 0.7551863491535187\n",
      "Step 20, loss: 0.7442765951156616\n",
      "Step 30, loss: 0.7232218861579895\n",
      "Validation loss: 0.7957557916641236\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.78      0.68       187\n",
      "           1       0.67      0.70      0.68       205\n",
      "           2       0.00      0.00      0.00        62\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       454\n",
      "   macro avg       0.43      0.49      0.46       454\n",
      "weighted avg       0.55      0.64      0.59       454\n",
      "\n",
      "Loss improved, saving 5\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10, loss: 0.6932547926902771\n",
      "Step 20, loss: 0.7062156915664672\n",
      "Step 30, loss: 0.7756695747375488\n",
      "Validation loss: 0.8021219968795776\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.79      0.69       187\n",
      "           1       0.68      0.71      0.70       205\n",
      "           2       0.00      0.00      0.00        62\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       454\n",
      "   macro avg       0.43      0.50      0.46       454\n",
      "weighted avg       0.56      0.64      0.60       454\n",
      "\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10, loss: 0.7203298568725586\n",
      "Step 20, loss: 0.6815254032611847\n",
      "Step 30, loss: 0.6797642767429352\n",
      "Validation loss: 0.7802448709805806\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69       187\n",
      "           1       0.66      0.78      0.71       205\n",
      "           2       0.00      0.00      0.00        62\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       454\n",
      "   macro avg       0.44      0.50      0.47       454\n",
      "weighted avg       0.57      0.65      0.61       454\n",
      "\n",
      "Loss improved, saving 7\n",
      "Epoch 5\n",
      "Step 10, loss: 0.6682704806327819\n",
      "Step 20, loss: 0.6600123047828674\n",
      "Step 30, loss: 0.6680908471345901\n",
      "Validation loss: 0.7644646724065145\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.74      0.68       187\n",
      "           1       0.66      0.75      0.70       205\n",
      "           2       0.00      0.00      0.00        62\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       454\n",
      "   macro avg       0.43      0.50      0.46       454\n",
      "weighted avg       0.56      0.64      0.60       454\n",
      "\n",
      "Loss improved, saving 8\n",
      "Epoch 6\n",
      "Step 10, loss: 0.6984960019588471\n",
      "Step 20, loss: 0.6494990527629853\n",
      "Step 30, loss: 0.647668081521988\n",
      "Validation loss: 0.7599656065305074\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.73      0.68       187\n",
      "           1       0.65      0.76      0.70       205\n",
      "           2       0.25      0.02      0.03        62\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       454\n",
      "   macro avg       0.52      0.50      0.47       454\n",
      "weighted avg       0.59      0.65      0.60       454\n",
      "\n",
      "Loss improved, saving 9\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "  print(\"Epoch\", i + 1)\n",
    "  total_epoch += 1\n",
    "  train_epoch(resolver, optimizer, train_dl)\n",
    "  loss, labels = evaluate(resolver, optimizer, valid_dl)\n",
    "  if loss < best_loss:\n",
    "    best_loss = loss\n",
    "    print(f\"Loss improved, saving {total_epoch}\")\n",
    "    torch.save(resolver.state_dict(), data_path/\"model_best.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f4932cc048bdd80fb3ed8a30a40b18a90d93d72a"
   },
   "source": [
    "## Fin: get the predictions and submit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "3a64168aacfb251830ea35d8f29451eb9aaedb49"
   },
   "outputs": [],
   "source": [
    "resolver.load_state_dict(torch.load(data_path/\"model_best.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "bf35cc404ad90fefb7713450b87acadd3e0110a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.6942235808523874\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.78      0.71       874\n",
      "           1       0.72      0.74      0.73       925\n",
      "           2       0.57      0.02      0.04       201\n",
      "\n",
      "   micro avg       0.69      0.69      0.69      2000\n",
      "   macro avg       0.65      0.52      0.50      2000\n",
      "weighted avg       0.68      0.69      0.66      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss, res = evaluate(resolver, optimizer, test_dl, True)\n",
    "res_s = np.exp(res)  # don't forget that we have log-softmax outputs:\n",
    "submission = pd.DataFrame(res_s, index=train[\"ID\"], columns=[\"A\", \"B\", \"NEITHER\"])\n",
    "submission.to_csv(\"submission.csv\", index=\"id\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
