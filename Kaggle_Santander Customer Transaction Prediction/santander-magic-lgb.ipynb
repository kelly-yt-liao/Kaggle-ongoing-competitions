{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fb9097ae88608c29c159c1443947bc699486827c"
   },
   "source": [
    "# Santander Customer Transaction Prediction\n",
    "## Can you identify who will make a transaction?\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/kaggle-organizations/141/thumbnail.jpg?r=890\"\n",
    "     alt=\"Markdown Monster icon\" width=\"200px\"\n",
    "     style=\"float: left; margin-right: 10px;\" />\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.csv', 'train.csv', 'sample_submission.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import seaborn as sns\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7b6573f10ae5a7a444eed504c829a7f8af9a3138"
   },
   "source": [
    "# Load Data & Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "06cd64c0f3127126bdc26a2e6c58c776241a17d8"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/train.csv')\n",
    "test_df = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "073d6a5c3be3de1954c5f50b42de85ffd9dce70e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200000, 201), (200000, 202))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape, train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "913b6742afe21df29fb375b827b13fd0fe216206"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>var_10</th>\n",
       "      <th>var_11</th>\n",
       "      <th>var_12</th>\n",
       "      <th>var_13</th>\n",
       "      <th>var_14</th>\n",
       "      <th>var_15</th>\n",
       "      <th>var_16</th>\n",
       "      <th>var_17</th>\n",
       "      <th>var_18</th>\n",
       "      <th>var_19</th>\n",
       "      <th>var_20</th>\n",
       "      <th>var_21</th>\n",
       "      <th>var_22</th>\n",
       "      <th>var_23</th>\n",
       "      <th>var_24</th>\n",
       "      <th>var_25</th>\n",
       "      <th>var_26</th>\n",
       "      <th>var_27</th>\n",
       "      <th>var_28</th>\n",
       "      <th>var_29</th>\n",
       "      <th>var_30</th>\n",
       "      <th>var_31</th>\n",
       "      <th>var_32</th>\n",
       "      <th>var_33</th>\n",
       "      <th>var_34</th>\n",
       "      <th>var_35</th>\n",
       "      <th>var_36</th>\n",
       "      <th>var_37</th>\n",
       "      <th>...</th>\n",
       "      <th>var_160</th>\n",
       "      <th>var_161</th>\n",
       "      <th>var_162</th>\n",
       "      <th>var_163</th>\n",
       "      <th>var_164</th>\n",
       "      <th>var_165</th>\n",
       "      <th>var_166</th>\n",
       "      <th>var_167</th>\n",
       "      <th>var_168</th>\n",
       "      <th>var_169</th>\n",
       "      <th>var_170</th>\n",
       "      <th>var_171</th>\n",
       "      <th>var_172</th>\n",
       "      <th>var_173</th>\n",
       "      <th>var_174</th>\n",
       "      <th>var_175</th>\n",
       "      <th>var_176</th>\n",
       "      <th>var_177</th>\n",
       "      <th>var_178</th>\n",
       "      <th>var_179</th>\n",
       "      <th>var_180</th>\n",
       "      <th>var_181</th>\n",
       "      <th>var_182</th>\n",
       "      <th>var_183</th>\n",
       "      <th>var_184</th>\n",
       "      <th>var_185</th>\n",
       "      <th>var_186</th>\n",
       "      <th>var_187</th>\n",
       "      <th>var_188</th>\n",
       "      <th>var_189</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>5.7470</td>\n",
       "      <td>2.9252</td>\n",
       "      <td>3.1821</td>\n",
       "      <td>14.0137</td>\n",
       "      <td>0.5745</td>\n",
       "      <td>8.7989</td>\n",
       "      <td>14.5691</td>\n",
       "      <td>5.7487</td>\n",
       "      <td>-7.2393</td>\n",
       "      <td>4.2840</td>\n",
       "      <td>30.7133</td>\n",
       "      <td>10.5350</td>\n",
       "      <td>16.2191</td>\n",
       "      <td>2.5791</td>\n",
       "      <td>2.4716</td>\n",
       "      <td>14.3831</td>\n",
       "      <td>13.4325</td>\n",
       "      <td>-5.1488</td>\n",
       "      <td>-0.4073</td>\n",
       "      <td>4.9306</td>\n",
       "      <td>5.9965</td>\n",
       "      <td>-0.3085</td>\n",
       "      <td>12.9041</td>\n",
       "      <td>-3.8766</td>\n",
       "      <td>16.8911</td>\n",
       "      <td>11.1920</td>\n",
       "      <td>10.5785</td>\n",
       "      <td>0.6764</td>\n",
       "      <td>7.8871</td>\n",
       "      <td>...</td>\n",
       "      <td>15.4576</td>\n",
       "      <td>5.3133</td>\n",
       "      <td>3.6159</td>\n",
       "      <td>5.0384</td>\n",
       "      <td>6.6760</td>\n",
       "      <td>12.6644</td>\n",
       "      <td>2.7004</td>\n",
       "      <td>-0.6975</td>\n",
       "      <td>9.5981</td>\n",
       "      <td>5.4879</td>\n",
       "      <td>-4.7645</td>\n",
       "      <td>-8.4254</td>\n",
       "      <td>20.8773</td>\n",
       "      <td>3.1531</td>\n",
       "      <td>18.5618</td>\n",
       "      <td>7.7423</td>\n",
       "      <td>-10.1245</td>\n",
       "      <td>13.7241</td>\n",
       "      <td>-3.5189</td>\n",
       "      <td>1.7202</td>\n",
       "      <td>-8.4051</td>\n",
       "      <td>9.0164</td>\n",
       "      <td>3.0657</td>\n",
       "      <td>14.3691</td>\n",
       "      <td>25.8398</td>\n",
       "      <td>5.8764</td>\n",
       "      <td>11.8411</td>\n",
       "      <td>-19.7159</td>\n",
       "      <td>17.5743</td>\n",
       "      <td>0.5857</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>8.0851</td>\n",
       "      <td>-0.4032</td>\n",
       "      <td>8.0585</td>\n",
       "      <td>14.0239</td>\n",
       "      <td>8.4135</td>\n",
       "      <td>5.4345</td>\n",
       "      <td>13.7003</td>\n",
       "      <td>13.8275</td>\n",
       "      <td>-15.5849</td>\n",
       "      <td>7.8000</td>\n",
       "      <td>28.5708</td>\n",
       "      <td>3.4287</td>\n",
       "      <td>2.7407</td>\n",
       "      <td>8.5524</td>\n",
       "      <td>3.3716</td>\n",
       "      <td>6.9779</td>\n",
       "      <td>13.8910</td>\n",
       "      <td>-11.7684</td>\n",
       "      <td>-2.5586</td>\n",
       "      <td>5.0464</td>\n",
       "      <td>0.5481</td>\n",
       "      <td>-9.2987</td>\n",
       "      <td>7.8755</td>\n",
       "      <td>1.2859</td>\n",
       "      <td>19.3710</td>\n",
       "      <td>11.3702</td>\n",
       "      <td>0.7399</td>\n",
       "      <td>2.7995</td>\n",
       "      <td>5.8434</td>\n",
       "      <td>...</td>\n",
       "      <td>29.4846</td>\n",
       "      <td>5.8683</td>\n",
       "      <td>3.8208</td>\n",
       "      <td>15.8348</td>\n",
       "      <td>-5.0121</td>\n",
       "      <td>15.1345</td>\n",
       "      <td>3.2003</td>\n",
       "      <td>9.3192</td>\n",
       "      <td>3.8821</td>\n",
       "      <td>5.7999</td>\n",
       "      <td>5.5378</td>\n",
       "      <td>5.0988</td>\n",
       "      <td>22.0330</td>\n",
       "      <td>5.5134</td>\n",
       "      <td>30.2645</td>\n",
       "      <td>10.4968</td>\n",
       "      <td>-7.2352</td>\n",
       "      <td>16.5721</td>\n",
       "      <td>-7.3477</td>\n",
       "      <td>11.0752</td>\n",
       "      <td>-5.5937</td>\n",
       "      <td>9.4878</td>\n",
       "      <td>-14.9100</td>\n",
       "      <td>9.4245</td>\n",
       "      <td>22.5441</td>\n",
       "      <td>-4.8622</td>\n",
       "      <td>7.6543</td>\n",
       "      <td>-15.9319</td>\n",
       "      <td>13.3175</td>\n",
       "      <td>-0.3566</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>5.9525</td>\n",
       "      <td>-0.3249</td>\n",
       "      <td>-11.2648</td>\n",
       "      <td>14.1929</td>\n",
       "      <td>7.3124</td>\n",
       "      <td>7.5244</td>\n",
       "      <td>14.6472</td>\n",
       "      <td>7.6782</td>\n",
       "      <td>-1.7395</td>\n",
       "      <td>4.7011</td>\n",
       "      <td>20.4775</td>\n",
       "      <td>17.7559</td>\n",
       "      <td>18.1377</td>\n",
       "      <td>1.2145</td>\n",
       "      <td>3.5137</td>\n",
       "      <td>5.6777</td>\n",
       "      <td>13.2177</td>\n",
       "      <td>-7.9940</td>\n",
       "      <td>-2.9029</td>\n",
       "      <td>5.8463</td>\n",
       "      <td>6.1439</td>\n",
       "      <td>-11.1025</td>\n",
       "      <td>12.4858</td>\n",
       "      <td>-2.2871</td>\n",
       "      <td>19.0422</td>\n",
       "      <td>11.0449</td>\n",
       "      <td>4.1087</td>\n",
       "      <td>4.6974</td>\n",
       "      <td>6.9346</td>\n",
       "      <td>...</td>\n",
       "      <td>13.2070</td>\n",
       "      <td>5.8442</td>\n",
       "      <td>4.7086</td>\n",
       "      <td>5.7141</td>\n",
       "      <td>-1.0410</td>\n",
       "      <td>20.5092</td>\n",
       "      <td>3.2790</td>\n",
       "      <td>-5.5952</td>\n",
       "      <td>7.3176</td>\n",
       "      <td>5.7690</td>\n",
       "      <td>-7.0927</td>\n",
       "      <td>-3.9116</td>\n",
       "      <td>7.2569</td>\n",
       "      <td>-5.8234</td>\n",
       "      <td>25.6820</td>\n",
       "      <td>10.9202</td>\n",
       "      <td>-0.3104</td>\n",
       "      <td>8.8438</td>\n",
       "      <td>-9.7009</td>\n",
       "      <td>2.4013</td>\n",
       "      <td>-4.2935</td>\n",
       "      <td>9.3908</td>\n",
       "      <td>-13.2648</td>\n",
       "      <td>3.1545</td>\n",
       "      <td>23.0866</td>\n",
       "      <td>-5.3000</td>\n",
       "      <td>5.3745</td>\n",
       "      <td>-6.2660</td>\n",
       "      <td>10.1934</td>\n",
       "      <td>-0.8417</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>8.2450</td>\n",
       "      <td>2.3061</td>\n",
       "      <td>2.8102</td>\n",
       "      <td>13.8463</td>\n",
       "      <td>11.9704</td>\n",
       "      <td>6.4569</td>\n",
       "      <td>14.8372</td>\n",
       "      <td>10.7430</td>\n",
       "      <td>-0.4299</td>\n",
       "      <td>15.9426</td>\n",
       "      <td>13.7257</td>\n",
       "      <td>20.3010</td>\n",
       "      <td>12.5579</td>\n",
       "      <td>6.8202</td>\n",
       "      <td>2.7229</td>\n",
       "      <td>12.1354</td>\n",
       "      <td>13.7367</td>\n",
       "      <td>0.8135</td>\n",
       "      <td>-0.9059</td>\n",
       "      <td>5.9070</td>\n",
       "      <td>2.8407</td>\n",
       "      <td>-15.2398</td>\n",
       "      <td>10.4407</td>\n",
       "      <td>-2.5731</td>\n",
       "      <td>6.1796</td>\n",
       "      <td>10.6093</td>\n",
       "      <td>-5.9158</td>\n",
       "      <td>8.1723</td>\n",
       "      <td>2.8521</td>\n",
       "      <td>...</td>\n",
       "      <td>31.8833</td>\n",
       "      <td>5.9684</td>\n",
       "      <td>7.2084</td>\n",
       "      <td>3.8899</td>\n",
       "      <td>-11.0882</td>\n",
       "      <td>17.2502</td>\n",
       "      <td>2.5881</td>\n",
       "      <td>-2.7018</td>\n",
       "      <td>0.5641</td>\n",
       "      <td>5.3430</td>\n",
       "      <td>-7.1541</td>\n",
       "      <td>-6.1920</td>\n",
       "      <td>18.2366</td>\n",
       "      <td>11.7134</td>\n",
       "      <td>14.7483</td>\n",
       "      <td>8.1013</td>\n",
       "      <td>11.8771</td>\n",
       "      <td>13.9552</td>\n",
       "      <td>-10.4701</td>\n",
       "      <td>5.6961</td>\n",
       "      <td>-3.7546</td>\n",
       "      <td>8.4117</td>\n",
       "      <td>1.8986</td>\n",
       "      <td>7.2601</td>\n",
       "      <td>-0.4639</td>\n",
       "      <td>-0.0498</td>\n",
       "      <td>7.9336</td>\n",
       "      <td>-12.8279</td>\n",
       "      <td>12.4124</td>\n",
       "      <td>1.8489</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>7.6784</td>\n",
       "      <td>-9.4458</td>\n",
       "      <td>-12.1419</td>\n",
       "      <td>13.8481</td>\n",
       "      <td>7.8895</td>\n",
       "      <td>7.7894</td>\n",
       "      <td>15.0553</td>\n",
       "      <td>8.4871</td>\n",
       "      <td>-3.0680</td>\n",
       "      <td>6.5263</td>\n",
       "      <td>11.3152</td>\n",
       "      <td>21.4246</td>\n",
       "      <td>18.9608</td>\n",
       "      <td>10.1102</td>\n",
       "      <td>2.7142</td>\n",
       "      <td>14.2080</td>\n",
       "      <td>13.5433</td>\n",
       "      <td>3.1736</td>\n",
       "      <td>-3.3423</td>\n",
       "      <td>5.9015</td>\n",
       "      <td>7.9352</td>\n",
       "      <td>-3.1582</td>\n",
       "      <td>9.4668</td>\n",
       "      <td>-0.0083</td>\n",
       "      <td>19.3239</td>\n",
       "      <td>12.4057</td>\n",
       "      <td>0.6329</td>\n",
       "      <td>2.7922</td>\n",
       "      <td>5.8184</td>\n",
       "      <td>...</td>\n",
       "      <td>33.5107</td>\n",
       "      <td>5.6953</td>\n",
       "      <td>5.4663</td>\n",
       "      <td>18.2201</td>\n",
       "      <td>6.5769</td>\n",
       "      <td>21.2607</td>\n",
       "      <td>3.2304</td>\n",
       "      <td>-1.7759</td>\n",
       "      <td>3.1283</td>\n",
       "      <td>5.5518</td>\n",
       "      <td>1.4493</td>\n",
       "      <td>-2.6627</td>\n",
       "      <td>19.8056</td>\n",
       "      <td>2.3705</td>\n",
       "      <td>18.4685</td>\n",
       "      <td>16.3309</td>\n",
       "      <td>-3.3456</td>\n",
       "      <td>13.5261</td>\n",
       "      <td>1.7189</td>\n",
       "      <td>5.1743</td>\n",
       "      <td>-7.6938</td>\n",
       "      <td>9.7685</td>\n",
       "      <td>4.8910</td>\n",
       "      <td>12.2198</td>\n",
       "      <td>11.8503</td>\n",
       "      <td>-7.8931</td>\n",
       "      <td>6.4209</td>\n",
       "      <td>5.9270</td>\n",
       "      <td>16.0201</td>\n",
       "      <td>-0.2829</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1   ...     var_196  var_197  var_198  var_199\n",
       "0  train_0       0   8.9255 -6.7863   ...      7.8784   8.5635  12.7803  -1.0914\n",
       "1  train_1       0  11.5006 -4.1473   ...      8.1267   8.7889  18.3560   1.9518\n",
       "2  train_2       0   8.6093 -2.7457   ...     -6.5213   8.2675  14.7222   0.3965\n",
       "3  train_3       0  11.0604 -2.1518   ...     -2.9275  10.2922  17.9697  -8.9996\n",
       "4  train_4       0   9.8369 -1.4834   ...      3.9267   9.5031  17.9974  -8.8104\n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "ba971dcc906dd67adb11928ab1735ad5be3735b7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>var_10</th>\n",
       "      <th>var_11</th>\n",
       "      <th>var_12</th>\n",
       "      <th>var_13</th>\n",
       "      <th>var_14</th>\n",
       "      <th>var_15</th>\n",
       "      <th>var_16</th>\n",
       "      <th>var_17</th>\n",
       "      <th>var_18</th>\n",
       "      <th>var_19</th>\n",
       "      <th>var_20</th>\n",
       "      <th>var_21</th>\n",
       "      <th>var_22</th>\n",
       "      <th>var_23</th>\n",
       "      <th>var_24</th>\n",
       "      <th>var_25</th>\n",
       "      <th>var_26</th>\n",
       "      <th>var_27</th>\n",
       "      <th>var_28</th>\n",
       "      <th>var_29</th>\n",
       "      <th>var_30</th>\n",
       "      <th>var_31</th>\n",
       "      <th>var_32</th>\n",
       "      <th>var_33</th>\n",
       "      <th>var_34</th>\n",
       "      <th>var_35</th>\n",
       "      <th>var_36</th>\n",
       "      <th>var_37</th>\n",
       "      <th>var_38</th>\n",
       "      <th>...</th>\n",
       "      <th>var_160</th>\n",
       "      <th>var_161</th>\n",
       "      <th>var_162</th>\n",
       "      <th>var_163</th>\n",
       "      <th>var_164</th>\n",
       "      <th>var_165</th>\n",
       "      <th>var_166</th>\n",
       "      <th>var_167</th>\n",
       "      <th>var_168</th>\n",
       "      <th>var_169</th>\n",
       "      <th>var_170</th>\n",
       "      <th>var_171</th>\n",
       "      <th>var_172</th>\n",
       "      <th>var_173</th>\n",
       "      <th>var_174</th>\n",
       "      <th>var_175</th>\n",
       "      <th>var_176</th>\n",
       "      <th>var_177</th>\n",
       "      <th>var_178</th>\n",
       "      <th>var_179</th>\n",
       "      <th>var_180</th>\n",
       "      <th>var_181</th>\n",
       "      <th>var_182</th>\n",
       "      <th>var_183</th>\n",
       "      <th>var_184</th>\n",
       "      <th>var_185</th>\n",
       "      <th>var_186</th>\n",
       "      <th>var_187</th>\n",
       "      <th>var_188</th>\n",
       "      <th>var_189</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>11.0656</td>\n",
       "      <td>7.7798</td>\n",
       "      <td>12.9536</td>\n",
       "      <td>9.4292</td>\n",
       "      <td>11.4327</td>\n",
       "      <td>-2.3805</td>\n",
       "      <td>5.8493</td>\n",
       "      <td>18.2675</td>\n",
       "      <td>2.1337</td>\n",
       "      <td>8.8100</td>\n",
       "      <td>-2.0248</td>\n",
       "      <td>-4.3554</td>\n",
       "      <td>13.9696</td>\n",
       "      <td>0.3458</td>\n",
       "      <td>7.5408</td>\n",
       "      <td>14.5001</td>\n",
       "      <td>7.7028</td>\n",
       "      <td>-19.0919</td>\n",
       "      <td>15.5806</td>\n",
       "      <td>16.1763</td>\n",
       "      <td>3.7088</td>\n",
       "      <td>18.8064</td>\n",
       "      <td>1.5899</td>\n",
       "      <td>3.0654</td>\n",
       "      <td>6.4509</td>\n",
       "      <td>14.1192</td>\n",
       "      <td>-9.4902</td>\n",
       "      <td>-2.1917</td>\n",
       "      <td>5.7107</td>\n",
       "      <td>3.7864</td>\n",
       "      <td>-1.7981</td>\n",
       "      <td>9.2645</td>\n",
       "      <td>2.0657</td>\n",
       "      <td>12.7753</td>\n",
       "      <td>11.3334</td>\n",
       "      <td>8.1462</td>\n",
       "      <td>-0.0610</td>\n",
       "      <td>3.5331</td>\n",
       "      <td>9.7804</td>\n",
       "      <td>...</td>\n",
       "      <td>5.9232</td>\n",
       "      <td>5.4113</td>\n",
       "      <td>3.8302</td>\n",
       "      <td>5.7380</td>\n",
       "      <td>-8.6105</td>\n",
       "      <td>22.9530</td>\n",
       "      <td>2.5531</td>\n",
       "      <td>-0.2836</td>\n",
       "      <td>4.3416</td>\n",
       "      <td>5.1855</td>\n",
       "      <td>4.2603</td>\n",
       "      <td>1.6779</td>\n",
       "      <td>29.0849</td>\n",
       "      <td>8.4685</td>\n",
       "      <td>18.1317</td>\n",
       "      <td>12.2818</td>\n",
       "      <td>-0.6912</td>\n",
       "      <td>10.2226</td>\n",
       "      <td>-5.5579</td>\n",
       "      <td>2.2926</td>\n",
       "      <td>-4.5358</td>\n",
       "      <td>10.3903</td>\n",
       "      <td>-15.4937</td>\n",
       "      <td>3.9697</td>\n",
       "      <td>31.3521</td>\n",
       "      <td>-1.1651</td>\n",
       "      <td>9.2874</td>\n",
       "      <td>-23.5705</td>\n",
       "      <td>13.2643</td>\n",
       "      <td>1.6591</td>\n",
       "      <td>-2.1556</td>\n",
       "      <td>11.8495</td>\n",
       "      <td>-1.4300</td>\n",
       "      <td>2.4508</td>\n",
       "      <td>13.7112</td>\n",
       "      <td>2.4669</td>\n",
       "      <td>4.3654</td>\n",
       "      <td>10.7200</td>\n",
       "      <td>15.4722</td>\n",
       "      <td>-8.7197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>8.5304</td>\n",
       "      <td>1.2543</td>\n",
       "      <td>11.3047</td>\n",
       "      <td>5.1858</td>\n",
       "      <td>9.1974</td>\n",
       "      <td>-4.0117</td>\n",
       "      <td>6.0196</td>\n",
       "      <td>18.6316</td>\n",
       "      <td>-4.4131</td>\n",
       "      <td>5.9739</td>\n",
       "      <td>-1.3809</td>\n",
       "      <td>-0.3310</td>\n",
       "      <td>14.1129</td>\n",
       "      <td>2.5667</td>\n",
       "      <td>5.4988</td>\n",
       "      <td>14.1853</td>\n",
       "      <td>7.0196</td>\n",
       "      <td>4.6564</td>\n",
       "      <td>29.1609</td>\n",
       "      <td>0.0910</td>\n",
       "      <td>12.1469</td>\n",
       "      <td>3.1389</td>\n",
       "      <td>5.2578</td>\n",
       "      <td>2.4228</td>\n",
       "      <td>16.2064</td>\n",
       "      <td>13.5023</td>\n",
       "      <td>-5.2341</td>\n",
       "      <td>-3.6648</td>\n",
       "      <td>5.7080</td>\n",
       "      <td>2.9965</td>\n",
       "      <td>-10.4720</td>\n",
       "      <td>11.4938</td>\n",
       "      <td>-0.9660</td>\n",
       "      <td>15.3445</td>\n",
       "      <td>10.6361</td>\n",
       "      <td>0.8966</td>\n",
       "      <td>6.7428</td>\n",
       "      <td>2.3421</td>\n",
       "      <td>12.8678</td>\n",
       "      <td>...</td>\n",
       "      <td>30.9641</td>\n",
       "      <td>5.6723</td>\n",
       "      <td>3.6873</td>\n",
       "      <td>13.0429</td>\n",
       "      <td>-10.6572</td>\n",
       "      <td>15.5134</td>\n",
       "      <td>3.2185</td>\n",
       "      <td>9.0535</td>\n",
       "      <td>7.0535</td>\n",
       "      <td>5.3924</td>\n",
       "      <td>-0.7720</td>\n",
       "      <td>-8.1783</td>\n",
       "      <td>29.9227</td>\n",
       "      <td>-5.6274</td>\n",
       "      <td>10.5018</td>\n",
       "      <td>9.6083</td>\n",
       "      <td>-0.4935</td>\n",
       "      <td>8.1696</td>\n",
       "      <td>-4.3605</td>\n",
       "      <td>5.2110</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>12.0030</td>\n",
       "      <td>-10.3812</td>\n",
       "      <td>5.8496</td>\n",
       "      <td>25.1958</td>\n",
       "      <td>-8.8468</td>\n",
       "      <td>11.8263</td>\n",
       "      <td>-8.7112</td>\n",
       "      <td>15.9072</td>\n",
       "      <td>0.9812</td>\n",
       "      <td>10.6165</td>\n",
       "      <td>8.8349</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>10.1282</td>\n",
       "      <td>15.5765</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>-1.4852</td>\n",
       "      <td>9.8714</td>\n",
       "      <td>19.1293</td>\n",
       "      <td>-20.9760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>5.4827</td>\n",
       "      <td>-10.3581</td>\n",
       "      <td>10.1407</td>\n",
       "      <td>7.0479</td>\n",
       "      <td>10.2628</td>\n",
       "      <td>9.8052</td>\n",
       "      <td>4.8950</td>\n",
       "      <td>20.2537</td>\n",
       "      <td>1.5233</td>\n",
       "      <td>8.3442</td>\n",
       "      <td>-4.7057</td>\n",
       "      <td>-3.0422</td>\n",
       "      <td>13.6751</td>\n",
       "      <td>3.8183</td>\n",
       "      <td>10.8535</td>\n",
       "      <td>14.2126</td>\n",
       "      <td>9.8837</td>\n",
       "      <td>2.6541</td>\n",
       "      <td>21.2181</td>\n",
       "      <td>20.8163</td>\n",
       "      <td>12.4666</td>\n",
       "      <td>12.3696</td>\n",
       "      <td>4.7473</td>\n",
       "      <td>2.7936</td>\n",
       "      <td>5.2189</td>\n",
       "      <td>13.5670</td>\n",
       "      <td>-15.4246</td>\n",
       "      <td>-0.1655</td>\n",
       "      <td>7.2633</td>\n",
       "      <td>3.4310</td>\n",
       "      <td>-9.1508</td>\n",
       "      <td>9.7320</td>\n",
       "      <td>3.1062</td>\n",
       "      <td>22.3076</td>\n",
       "      <td>11.9593</td>\n",
       "      <td>9.9255</td>\n",
       "      <td>4.0702</td>\n",
       "      <td>4.9934</td>\n",
       "      <td>8.0667</td>\n",
       "      <td>...</td>\n",
       "      <td>39.3654</td>\n",
       "      <td>5.5228</td>\n",
       "      <td>3.3159</td>\n",
       "      <td>4.3324</td>\n",
       "      <td>-0.5382</td>\n",
       "      <td>13.3009</td>\n",
       "      <td>3.1243</td>\n",
       "      <td>-4.1731</td>\n",
       "      <td>1.2330</td>\n",
       "      <td>6.1513</td>\n",
       "      <td>-0.0391</td>\n",
       "      <td>1.4950</td>\n",
       "      <td>16.8874</td>\n",
       "      <td>-2.9787</td>\n",
       "      <td>27.4035</td>\n",
       "      <td>15.8819</td>\n",
       "      <td>-10.9660</td>\n",
       "      <td>15.6415</td>\n",
       "      <td>-9.4056</td>\n",
       "      <td>4.4611</td>\n",
       "      <td>-3.0835</td>\n",
       "      <td>8.5549</td>\n",
       "      <td>-2.8517</td>\n",
       "      <td>13.4770</td>\n",
       "      <td>24.4721</td>\n",
       "      <td>-3.4824</td>\n",
       "      <td>4.9178</td>\n",
       "      <td>-2.0720</td>\n",
       "      <td>11.5390</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>-0.7484</td>\n",
       "      <td>10.9935</td>\n",
       "      <td>1.9803</td>\n",
       "      <td>2.1800</td>\n",
       "      <td>12.9813</td>\n",
       "      <td>2.1281</td>\n",
       "      <td>-7.1086</td>\n",
       "      <td>7.0618</td>\n",
       "      <td>19.8956</td>\n",
       "      <td>-23.1794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>8.5374</td>\n",
       "      <td>-1.3222</td>\n",
       "      <td>12.0220</td>\n",
       "      <td>6.5749</td>\n",
       "      <td>8.8458</td>\n",
       "      <td>3.1744</td>\n",
       "      <td>4.9397</td>\n",
       "      <td>20.5660</td>\n",
       "      <td>3.3755</td>\n",
       "      <td>7.4578</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>-5.0659</td>\n",
       "      <td>14.0526</td>\n",
       "      <td>13.5010</td>\n",
       "      <td>8.7660</td>\n",
       "      <td>14.7352</td>\n",
       "      <td>10.0383</td>\n",
       "      <td>-15.3508</td>\n",
       "      <td>2.1273</td>\n",
       "      <td>21.4797</td>\n",
       "      <td>14.5372</td>\n",
       "      <td>12.5527</td>\n",
       "      <td>2.9707</td>\n",
       "      <td>4.2398</td>\n",
       "      <td>13.7796</td>\n",
       "      <td>14.1408</td>\n",
       "      <td>1.0061</td>\n",
       "      <td>-1.3479</td>\n",
       "      <td>5.2570</td>\n",
       "      <td>6.5911</td>\n",
       "      <td>6.2161</td>\n",
       "      <td>9.5540</td>\n",
       "      <td>2.3628</td>\n",
       "      <td>10.2124</td>\n",
       "      <td>10.8047</td>\n",
       "      <td>-2.5588</td>\n",
       "      <td>6.0720</td>\n",
       "      <td>3.2613</td>\n",
       "      <td>16.5632</td>\n",
       "      <td>...</td>\n",
       "      <td>19.7251</td>\n",
       "      <td>5.3882</td>\n",
       "      <td>3.6775</td>\n",
       "      <td>7.4753</td>\n",
       "      <td>-11.0780</td>\n",
       "      <td>24.8712</td>\n",
       "      <td>2.6415</td>\n",
       "      <td>2.2673</td>\n",
       "      <td>7.2788</td>\n",
       "      <td>5.6406</td>\n",
       "      <td>7.2048</td>\n",
       "      <td>3.4504</td>\n",
       "      <td>2.4130</td>\n",
       "      <td>11.1674</td>\n",
       "      <td>14.5499</td>\n",
       "      <td>10.6151</td>\n",
       "      <td>-5.7922</td>\n",
       "      <td>13.9407</td>\n",
       "      <td>7.1078</td>\n",
       "      <td>1.1019</td>\n",
       "      <td>9.4590</td>\n",
       "      <td>9.8243</td>\n",
       "      <td>5.9917</td>\n",
       "      <td>5.1634</td>\n",
       "      <td>8.1154</td>\n",
       "      <td>3.6638</td>\n",
       "      <td>3.3102</td>\n",
       "      <td>-19.7819</td>\n",
       "      <td>13.4499</td>\n",
       "      <td>1.3104</td>\n",
       "      <td>9.5702</td>\n",
       "      <td>9.0766</td>\n",
       "      <td>1.6580</td>\n",
       "      <td>3.5813</td>\n",
       "      <td>15.1874</td>\n",
       "      <td>3.1656</td>\n",
       "      <td>3.9567</td>\n",
       "      <td>9.2295</td>\n",
       "      <td>13.0168</td>\n",
       "      <td>-4.2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>11.7058</td>\n",
       "      <td>-0.1327</td>\n",
       "      <td>14.1295</td>\n",
       "      <td>7.7506</td>\n",
       "      <td>9.1035</td>\n",
       "      <td>-8.5848</td>\n",
       "      <td>6.8595</td>\n",
       "      <td>10.6048</td>\n",
       "      <td>2.9890</td>\n",
       "      <td>7.1437</td>\n",
       "      <td>5.1025</td>\n",
       "      <td>-3.2827</td>\n",
       "      <td>14.1013</td>\n",
       "      <td>8.9672</td>\n",
       "      <td>4.7276</td>\n",
       "      <td>14.5811</td>\n",
       "      <td>11.8615</td>\n",
       "      <td>3.1480</td>\n",
       "      <td>18.0126</td>\n",
       "      <td>13.8006</td>\n",
       "      <td>1.6026</td>\n",
       "      <td>16.3059</td>\n",
       "      <td>6.7954</td>\n",
       "      <td>3.6015</td>\n",
       "      <td>13.6569</td>\n",
       "      <td>13.8807</td>\n",
       "      <td>8.6228</td>\n",
       "      <td>-2.2654</td>\n",
       "      <td>5.2255</td>\n",
       "      <td>7.0165</td>\n",
       "      <td>-15.6961</td>\n",
       "      <td>10.6239</td>\n",
       "      <td>-4.7674</td>\n",
       "      <td>17.5447</td>\n",
       "      <td>11.8668</td>\n",
       "      <td>3.0154</td>\n",
       "      <td>4.2546</td>\n",
       "      <td>6.7601</td>\n",
       "      <td>5.9613</td>\n",
       "      <td>...</td>\n",
       "      <td>22.8700</td>\n",
       "      <td>5.6688</td>\n",
       "      <td>6.1159</td>\n",
       "      <td>13.2433</td>\n",
       "      <td>-11.9785</td>\n",
       "      <td>26.2040</td>\n",
       "      <td>3.2348</td>\n",
       "      <td>-5.5775</td>\n",
       "      <td>5.7036</td>\n",
       "      <td>6.1717</td>\n",
       "      <td>-1.6039</td>\n",
       "      <td>-2.4866</td>\n",
       "      <td>17.2728</td>\n",
       "      <td>2.3640</td>\n",
       "      <td>14.0037</td>\n",
       "      <td>12.9165</td>\n",
       "      <td>-12.0311</td>\n",
       "      <td>10.1161</td>\n",
       "      <td>-8.7562</td>\n",
       "      <td>6.0889</td>\n",
       "      <td>-1.3620</td>\n",
       "      <td>10.3559</td>\n",
       "      <td>-7.4915</td>\n",
       "      <td>9.4588</td>\n",
       "      <td>3.9829</td>\n",
       "      <td>5.8580</td>\n",
       "      <td>8.3635</td>\n",
       "      <td>-24.8254</td>\n",
       "      <td>11.4928</td>\n",
       "      <td>1.6321</td>\n",
       "      <td>4.2259</td>\n",
       "      <td>9.1723</td>\n",
       "      <td>1.2835</td>\n",
       "      <td>3.3778</td>\n",
       "      <td>19.5542</td>\n",
       "      <td>-0.2860</td>\n",
       "      <td>-5.1612</td>\n",
       "      <td>7.2882</td>\n",
       "      <td>13.9260</td>\n",
       "      <td>-9.1846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code    var_0    var_1   ...     var_197  var_198  var_199\n",
       "0  test_0  11.0656   7.7798   ...     10.7200  15.4722  -8.7197\n",
       "1  test_1   8.5304   1.2543   ...      9.8714  19.1293 -20.9760\n",
       "2  test_2   5.4827 -10.3581   ...      7.0618  19.8956 -23.1794\n",
       "3  test_3   8.5374  -1.3222   ...      9.2295  13.0168  -4.2108\n",
       "4  test_4  11.7058  -0.1327   ...      7.2882  13.9260  -9.1846\n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "5d810d2b297aa690f35302648983fd32468549c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "76198ed9effbb06e7066212155217650d086de68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "9228adbcbbcbbe4ad5c9d32179a8b66b35c78883"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEKCAYAAADEovgeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAHi9JREFUeJzt3X9Mlef9//HnEQq1BQFRDpOgrSlLib/YWueIFNJjj7QiA1HiXNoq07hWZ4c0ZqXugwhqdTUbbc2MhGRr9zFdLFNYOe1Ejy3orMP+IJQGm5n17IttOWdDBGknFLy/f/jxZK5qj5WLY/H1SEjOue7rvu/3ldw5L+7rvs99bJZlWYiIiBg0KtgFiIjIyKewERER4xQ2IiJinMJGRESMU9iIiIhxChsRETFOYSMiIsYpbERExDiFjYiIGBca7AJuFM3NzYSHhwe7DBGRb5S+vj5SUlK+sp/C5v+Eh4eTnJwc7DJERL5R2traAuqnaTQRETFOYSMiIsYpbERExDiFjYiIGKewERER4xQ2IiJinMJGRESMU9iIiIhxChsRETFOYTOE+r4YDHYJcgPScSGix9UMqfBbQrhn3UvBLkNuMO88+2iwSxAJOmNhU1xczJtvvklsbCx1dXUAFBYW8tFHHwFw9uxZIiMjqa2t5dSpU8ybN48777wTgBkzZlBWVgZAa2srxcXFnDt3joyMDNavX4/NZuPMmTOsXbuWjz/+mISEBCoqKoiKisKyLDZv3kxDQwO33norW7duZcqUKaaGKSIiATA2jZaXl0dVVdUlbRUVFdTW1lJbW8vcuXNxOp3+ZRMnTvQvuxg0AKWlpZSXl1NfX4/H46GxsRGAyspKUlNTqa+vJzU1lcrKSgAaGxvxeDzU19dTXl5OaWmpqSGKiEiAjIXNzJkziYqKuuwyy7J4/fXXmT9//lW34fP56O3tJSUlBZvNRm5uLm63GwC3201ubi4Aubm5HDx48JJ2m81GSkoKPT09+Hy+IRyZiIhcq6Bcs3n77beJjY3ljjvu8LedOnWK3NxcIiIiKCws5N5778Xr9RIfH+/vEx8fj9frBaCzs5O4uDgAxo8fT2dnJ8AV17nY90r6+voCflT2legnCuRKrvfYEvmmC0rY1NXVXXJWExcXxxtvvEFMTAytra2sXr0al8sV8PZsNhs2m+26atLv2YhJOrZkpLphf89mYGCAAwcOMG/ePH9bWFgYMTExAEydOpWJEyfy0UcfYbfb6ejo8Pfr6OjAbrcDEBsb658e8/l8jB07FuCq64iISHAMe9gcPXqUyZMnXzLVdfr0aQYHL3wXob29HY/HQ2JiInFxcURERNDc3IxlWdTU1DBnzhwAHA4HNTU1AJdttyyL5uZmIiMjv3IKTUREzDI2jVZUVERTUxNdXV2kp6ezZs0a8vPzee2118jKyrqk7/Hjx3n++ecJDQ1l1KhRbNy4kejoaAA2bNjgv/U5PT2d9PR0AFauXElhYSHV1dVMmDCBiooKADIyMmhoaMDpdDJ69Gi2bNliaogiIhIgm2VZVrCLuBG0tbUNyby6vtQp/01f6pSRLNDPTj2uRkREjFPYiIiIcQobERExTmEjIiLGKWxERMQ4hY2IiBinsBEREeMUNiIiYpzCRkREjFPYiIiIcQobERExTmEjIiLGKWxERMQ4hY2IiBinsBEREeMUNiIiYpzCRkREjFPYiIiIcQobERExzljYFBcXk5qayvz58/1tL7zwAvfddx85OTnk5OTQ0NDgX7Zr1y6cTieZmZkcPnzY397Y2EhmZiZOp5PKykp/e3t7O/n5+TidTgoLC+nv7wegv7+fwsJCnE4n+fn5nDp1ytQQRUQkQMbCJi8vj6qqqi+1L1u2jNraWmpra8nIyADg5MmTuFwuXC4XVVVVbNy4kcHBQQYHBykrK6OqqgqXy0VdXR0nT54EYPv27SxbtowDBw4wZswYqqurAXjllVcYM2YMBw4cYNmyZWzfvt3UEEVEJEDGwmbmzJlERUUF1NftdpOVlUVYWBiJiYlMmjSJlpYWWlpamDRpEomJiYSFhZGVlYXb7cayLI4dO0ZmZiYACxYswO12A3Do0CEWLFgAQGZmJm+99RaWZZkZpIiIBGTYr9ns3r2b7OxsiouL6e7uBsDr9RIfH+/vY7fb8Xq9V2zv6upizJgxhIaGAhAfH4/X6/Vv61vf+hYAoaGhREZG0tXVNVzDExGRywgdzp0tWbKEVatWYbPZeO6559i6dSvPPPPMcJZwRX19fbS1tV3XNpKTk4eoGhlprvfYEvmmG9awGTdunP91fn4+jz32GHDhjKWjo8O/zOv1YrfbAS7bHhMTQ09PDwMDA4SGhtLR0eHvb7fb+fTTT4mPj2dgYICzZ88SExPzlbWFh4crLMQYHVsyUgX6j9SwTqP5fD7/64MHD5KUlASAw+HA5XLR399Pe3s7Ho+H6dOnM23aNDweD+3t7fT39+NyuXA4HNhsNmbNmsX+/fsB2LdvHw6Hw7+tffv2AbB//36+//3vY7PZhnOYIiLyX4yd2RQVFdHU1ERXVxfp6emsWbOGpqYmTpw4AUBCQgJlZWUAJCUl8dBDDzFv3jxCQkIoKSkhJCQEgJKSElasWMHg4CALFy70B9S6detYu3YtFRUVJCcnk5+fD8CiRYtYt24dTqeTqKgofv3rX5saooiIBMhm6VYt4MKp4FBMddyz7qUhqEZGkneefTTYJYgYE+hnp54gICIixilsRETEOIWNiIgYp7ARERHjFDYiImKcwkZERIxT2IiIiHEKGxERMU5hIyIixilsRETEOIWNiIgYp7ARERHjFDYiImKcwkZERIxT2IiIiHEKGxERMU5hIyIixilsRETEOIWNiIgYp7ARERHjjIVNcXExqampzJ8/39+2bds2HnzwQbKzs1m9ejU9PT0AnDp1iunTp5OTk0NOTg4lJSX+dVpbW8nOzsbpdLJp0yYsywLgzJkzFBQUMHfuXAoKCuju7gbAsiw2bdqE0+kkOzubDz74wNQQRUQkQMbCJi8vj6qqqkvaZs+eTV1dHa+++ip33HEHu3bt8i+bOHEitbW11NbWUlZW5m8vLS2lvLyc+vp6PB4PjY2NAFRWVpKamkp9fT2pqalUVlYC0NjYiMfjob6+nvLyckpLS00NUUREAmQsbGbOnElUVNQlbWlpaYSGhgKQkpJCR0fHVbfh8/no7e0lJSUFm81Gbm4ubrcbALfbTW5uLgC5ubkcPHjwknabzUZKSgo9PT34fL6hHp6IiFyDoF2z+eMf/0h6err//alTp8jNzeXhhx/m7bffBsDr9RIfH+/vEx8fj9frBaCzs5O4uDgAxo8fT2dn51euIyIiwREajJ3u3LmTkJAQfvCDHwAQFxfHG2+8QUxMDK2traxevRqXyxXw9mw2Gzab7bpq6uvro62t7bq2kZycfF3ry8h1vceWyDfdsIfN3r17efPNN/nd737nD4iwsDDCwsIAmDp1KhMnTuSjjz7CbrdfMtXW0dGB3W4HIDY2Fp/PR1xcHD6fj7FjxwJcdZ2rCQ8PV1iIMTq2ZKQK9B+pYZ1Ga2xspKqqip07dzJ69Gh/++nTpxkcHASgvb0dj8dDYmIicXFxRERE0NzcjGVZ1NTUMGfOHAAcDgc1NTUAl223LIvm5mYiIyP9020iIhIcxs5sioqKaGpqoquri/T0dNasWUNlZSX9/f0UFBQAMGPGDMrKyjh+/DjPP/88oaGhjBo1io0bNxIdHQ3Ahg0bKC4u5ty5c6Snp/uv86xcuZLCwkKqq6uZMGECFRUVAGRkZNDQ0IDT6WT06NFs2bLF1BBFRCRANuviF1ducm1tbUMy1XHPupeGoBoZSd559tFglyBiTKCfnXqCgIiIGKewERER4xQ2IiJinMJGRESMU9iIiIhxChsRETFOYSMiIsYpbERExDiFjYiIGKewERER4xQ2IiJinMJGRESMU9iIiIhxChsRETFOYSMiIsYpbERExDiFjYiIGKewERER4wIKm6VLlwbUJiIicjmhV1vY19fHv//9b7q6uuju7sayLAB6e3vxer3DUqCIiHzzXTVs/vCHP/Diiy/i8/nIy8vzh01ERAQPP/zwV268uLiYN998k9jYWOrq6gA4c+YMa9eu5eOPPyYhIYGKigqioqKwLIvNmzfT0NDArbfeytatW5kyZQoA+/btY+fOnQA8/vjjLFiwAIDW1laKi4s5d+4cGRkZrF+/HpvNdsV9iIhIcFx1Gm3p0qUcOnSIn//857jdbg4dOsShQ4f405/+FFDY5OXlUVVVdUlbZWUlqamp1NfXk5qaSmVlJQCNjY14PB7q6+spLy+ntLQUuBBOO3bsYM+ePbzyyivs2LGD7u5uAEpLSykvL6e+vh6Px0NjY+NV9yEiIsER0DWbRx55hHfffZdXX32Vmpoa/99XmTlz5pfOKNxuN7m5uQDk5uZy8ODBS9ptNhspKSn09PTg8/k4cuQIs2fPJjo6mqioKGbPns3hw4fx+Xz09vaSkpKCzWYjNzcXt9t91X2IiEhwXHUa7aJ169bR3t7O3XffTUhICID/A/5adXZ2EhcXB8D48ePp7OwEwOv1Eh8f7+8XHx+P1+v9Urvdbr9s+8X+V9uHiIgER0Bh09raymuvvYbNZhvSndtstiHf5tfdR19fH21tbde1r+Tk5OtaX0au6z22RL7pAgqbpKQk/vnPf/rPFq5HbGwsPp+PuLg4fD4fY8eOBS6csXR0dPj7dXR0YLfbsdvtNDU1+du9Xi/f+973rtj/avu4mvDwcIWFGKNjS0aqQP+RCuiaTVdXF1lZWSxfvpzHHnvM//d1OBwO//Wempoa5syZc0m7ZVk0NzcTGRlJXFwcaWlpHDlyhO7ubrq7uzly5AhpaWnExcURERFBc3MzlmVddlv/vQ8REQmOgM5s1qxZ87U2XlRURFNTE11dXaSnp7NmzRpWrlxJYWEh1dXVTJgwgYqKCgAyMjJoaGjA6XQyevRotmzZAkB0dDSrVq1i0aJFAKxevZro6GgANmzY4L/1OT09nfT0dIAr7kNERILDZl388sxNrq2tbUimOu5Z99IQVCMjyTvPPhrsEkSMCfSzM6Azm+985zv+i+xffPEFAwMDjB49mnfffff6qhQRkZtCQGHz3nvv+V9bloXb7aa5udlYUSIiMrJc81OfbTYbDzzwAEeOHDFRj4iIjEABndnU19f7X58/f57W1lbCw8ONFSUiIiNLQGHzxhtv+F+HhISQkJDAb37zG2NFiYjIyBJQ2DzzzDOm6xARkREsoGs2HR0drF69mtTUVFJTU1mzZs0l394XERG5moDCpri4GIfDweHDhzl8+DD3338/xcXFpmsTEZERIqCwOX36NAsXLiQ0NJTQ0FDy8vI4ffq06dpERGSECChsoqOjqa2tZXBwkMHBQWpra/2PjBEREfkqAYXNli1beP3115k9ezZpaWns37+frVu3mq5NRERGiIDuRnv++efZtm2b/1c3z5w5w7Zt23SXmoiIBCSgM5sPP/zwkp93jo6O1o9BiYhIwAIKm/Pnz9Pd3e1/f+bMGQYHB40VJSIiI0tA02g//vGPWbx4MQ8++CAAf/7zn7/2j6eJiMjNJ6Cwyc3NZerUqRw7dgyAHTt2cNdddxktTERERo6AwgbgrrvuUsCIiMjXcs0/MSAiInKtFDYiImKcwkZERIwL+JrNUPn73//O2rVr/e/b29t54oknOHv2LHv27GHs2LEAFBUVkZGRAcCuXbuorq5m1KhR/OIXv+C+++4DoLGxkc2bN3P+/Hny8/NZuXKlf5tFRUWcOXOGKVOm8Mtf/pKwsLBhHqmIiFw07Gc2kydPpra2ltraWvbu3cvo0aNxOp0ALFu2zL/sYtCcPHkSl8uFy+WiqqqKjRs3+p/RVlZWRlVVFS6Xi7q6Ok6ePAnA9u3bWbZsGQcOHGDMmDFUV1cP9zBFROQ/BHUa7a233iIxMZGEhIQr9nG73WRlZREWFkZiYiKTJk2ipaWFlpYWJk2aRGJiImFhYWRlZeF2u7Esi2PHjpGZmQnAggULcLvdwzUkERG5jGGfRvtPLpeL+fPn+9/v3r2bmpoapk6dylNPPUVUVBRer5cZM2b4+9jtdrxeLwDx8fGXtLe0tNDV1cWYMWMIDQ3197nY/2r6+vqu+xE8ycnJ17W+jFx6vJPc7IIWNv39/Rw6dIgnn3wSgCVLlrBq1SpsNhvPPfccW7duHdYHfYaHhyssxBgdWzJSBfqPVNCm0RobG5kyZQrjxo0DYNy4cYSEhDBq1Cjy8/N5//33gQtnLP/5E9Rerxe73X7F9piYGHp6ehgYGAAu/KS13W4fxpGJiMh/C1rYuFwusrKy/O99Pp//9cGDB0lKSgLA4XDgcrno7++nvb0dj8fD9OnTmTZtGh6Ph/b2dvr7+3G5XDgcDmw2G7NmzWL//v0A7Nu3D4fDMbyDExGRSwRlGu3zzz/n6NGjlJWV+dueffZZTpw4AUBCQoJ/WVJSEg899BDz5s0jJCSEkpISQkJCACgpKWHFihUMDg6ycOFCf0CtW7eOtWvXUlFRQXJyMvn5+cM8QhER+U82y7KsYBdxI2hraxuSefV71r00BNXISPLOs48GuwQRYwL97NQTBERExDiFjYiIGKewERER4xQ2IiJinMJGRESMU9iIiIhxChsRETFOYSMiIsYpbERExDiFjYiIGKewERER4xQ2IiJinMJGRESMU9iIiIhxChsRETFOYSMiIsYpbERExDiFjYiIGKewERER4xQ2IiJiXNDCxuFwkJ2dTU5ODnl5eQCcOXOGgoIC5s6dS0FBAd3d3QBYlsWmTZtwOp1kZ2fzwQcf+Lezb98+5s6dy9y5c9m3b5+/vbW1lezsbJxOJ5s2bcKyrOEdoIiI+AX1zObFF1+ktraWvXv3AlBZWUlqair19fWkpqZSWVkJQGNjIx6Ph/r6esrLyyktLQUuhNOOHTvYs2cPr7zyCjt27PAHVGlpKeXl5dTX1+PxeGhsbAzKGEVE5AabRnO73eTm5gKQm5vLwYMHL2m32WykpKTQ09ODz+fjyJEjzJ49m+joaKKiopg9ezaHDx/G5/PR29tLSkoKNpuN3Nxc3G53MIcmInJTCw3mzpcvX47NZmPx4sUsXryYzs5O4uLiABg/fjydnZ0AeL1e4uPj/evFx8fj9Xq/1G632y/bfrH/1fT19dHW1nZd40lOTr6u9WXkut5jS+SbLmhh8/LLL2O32+ns7KSgoIDJkydfstxms2Gz2YatnvDwcIWFGKNjS0aqQP+RCto0mt1uByA2Nhan00lLSwuxsbH4fD4AfD4fY8eO9fft6Ojwr9vR0YHdbv9Su9frvWz7xf4iIhIcQQmbzz//nN7eXv/rv/zlLyQlJeFwOKipqQGgpqaGOXPmAPjbLcuiubmZyMhI4uLiSEtL48iRI3R3d9Pd3c2RI0dIS0sjLi6OiIgImpubsSzrkm2JiMjwC8o0WmdnJ6tXrwZgcHCQ+fPnk56ezrRp0ygsLKS6upoJEyZQUVEBQEZGBg0NDTidTkaPHs2WLVsAiI6OZtWqVSxatAiA1atXEx0dDcCGDRsoLi7m3LlzpKenk56eHoSRiogIgM3SF1CAC/OOQzGvfs+6l4agGhlJ3nn20WCXIGJMoJ+dN9StzyIiMjIpbERExDiFjYiIGKewERER4xQ2IiJinMJGRESMU9iIiIhxChsRETFOYSMiIsYpbERExDiFjYiIGKewERER4xQ2IiJinMJGRESMU9iIiIhxChsRETFOYSMiIsYpbERExDiFjYiIGDfsYfPpp5/yyCOPMG/ePLKysnjxxRcBeOGFF7jvvvvIyckhJyeHhoYG/zq7du3C6XSSmZnJ4cOH/e2NjY1kZmbidDqprKz0t7e3t5Ofn4/T6aSwsJD+/v7hG6CIiHxJ6HDvMCQkhKeeeoopU6bQ29vLwoULmT17NgDLli1j+fLll/Q/efIkLpcLl8uF1+uloKCA/fv3A1BWVsZvf/tb7HY7ixYtwuFwcNddd7F9+3aWLVtGVlYWJSUlVFdX86Mf/Wi4hyoiIv9n2M9s4uLimDJlCgARERFMnjwZr9d7xf5ut5usrCzCwsJITExk0qRJtLS00NLSwqRJk0hMTCQsLIysrCzcbjeWZXHs2DEyMzMBWLBgAW63e1jGJiIilxfUazanTp2ira2NGTNmALB7926ys7MpLi6mu7sbAK/XS3x8vH8du92O1+u9YntXVxdjxowhNPTCSVt8fPxVw0xERMwb9mm0iz777DOeeOIJnn76aSIiIliyZAmrVq3CZrPx3HPPsXXrVp555plhq6evr4+2trbr2kZycvIQVSMjzfUeWyLfdEEJmy+++IInnniC7Oxs5s6dC8C4ceP8y/Pz83nssceAC2csHR0d/mVerxe73Q5w2faYmBh6enoYGBggNDSUjo4Of/+rCQ8PV1iIMTq2ZKQK9B+pYZ9GsyyL9evXM3nyZAoKCvztPp/P//rgwYMkJSUB4HA4cLlc9Pf3097ejsfjYfr06UybNg2Px0N7ezv9/f24XC4cDgc2m41Zs2b5byLYt28fDodjeAcpIiKXGPYzm3feeYfa2lq+/e1vk5OTA0BRURF1dXWcOHECgISEBMrKygBISkrioYceYt68eYSEhFBSUkJISAgAJSUlrFixgsHBQRYuXOgPqHXr1rF27VoqKipITk4mPz9/uIcpIiL/wWZZlhXsIm4EbW1tQzLVcc+6l4agGhlJ3nn20WCXIGJMoJ+deoKAiIgYp7ARuQlYA33BLkFuQMN5XATt1mcRGT620HD+X9m0YJchN5iJJe8P2750ZiMiIsYpbERExDiFjYiIGKewERER4xQ2IiJinMJGRESMU9iIiIhxChsRETFOYSMiIsYpbERExDiFjYiIGKewERER4xQ2IiJinMJGRESMU9iIiIhxChsRETFOYSMiIsaN2LBpbGwkMzMTp9NJZWVlsMsREbmpjciwGRwcpKysjKqqKlwuF3V1dZw8eTLYZYmI3LRGZNi0tLQwadIkEhMTCQsLIysrC7fbHeyyRERuWiMybLxeL/Hx8f73drsdr9cbxIpERG5uocEu4EbR19dHW1vbdW/nf388cwiqkZFkKI6rIZG/J9gVyA1mKI7Nvr6+gPqNyLCx2+10dHT433u9Xux2+1XXSUlJMV2WiMhNa0ROo02bNg2Px0N7ezv9/f24XC4cDkewyxIRuWmNyDOb0NBQSkpKWLFiBYODgyxcuJCkpKRglyUictOyWZZlBbsIEREZ2UbkNJqIiNxYFDYiImKcwkaGlB4TJDeq4uJiUlNTmT9/frBLuSkpbGTI6DFBciPLy8ujqqoq2GXctBQ2MmT0mCC5kc2cOZOoqKhgl3HTUtjIkNFjgkTkShQ2IiJinMJGhszXeUyQiNwcFDYyZPSYIBG5Ej1BQIZUQ0MDW7Zs8T8m6PHHHw92SSIAFBUV0dTURFdXF7GxsaxZs4b8/Pxgl3XTUNiIiIhxmkYTERHjFDYiImKcwkZERIxT2IiIiHEKGxERMU5hIzIMenp62L17t/H9/PWvf+Xdd981vh+Ra6WwERkGPT09vPzyywH3tyyL8+fPX/N+mpqaeO+99655PRHT9D0bkWGwdu1a3G43d955J7NmzeLDDz+kp6eHgYEBfvazn/HAAw9w6tQpli9fzowZM/jggw+orKzk6NGjVFVVERkZyd13301YWBglJSWcPn2aDRs28MknnwDw9NNPY7fbWbx4MaNGjWLs2LH8z//8D/fee2+QRy5yQWiwCxC5GTz55JP87W9/o7a2loGBAc6dO0dERASnT59m8eLFzJkzB4B//OMfbNu2jZSUFLxeLzt37mTv3r3cfvvtLF26lLvvvhuAzZs3s3TpUu69914++eQTli9fzuuvv84Pf/hDbrvtNpYvXx7M4Yp8icJGZJhZlsWvfvUrjh8/zqhRo/B6vfzrX/8CYMKECaSkpADw/vvvM3PmTKKjowF48MEH8Xg8ABw9evSSH6br7e3ls88+G96BiFwDhY3IMHv11Vc5ffo0e/fu5ZZbbsHhcNDX1wfAbbfdFtA2zp8/z549ewgPDzdZqsiQ0Q0CIsPg9ttv9595nD17ltjYWG655RaOHTvGxx9/fNl1pk2bxvHjx+nu7mZgYID6+nr/srS0NH7/+9/737e1tX1pPyI3EoWNyDCIiYnhu9/9LvPnz+fEiRO0traSnZ1NbW0tkydPvuw6drudn/zkJ+Tn57NkyRISEhKIjIwEYP369f5tzJs3z3+n2/3338+BAwfIycnh7bffHrbxiXwV3Y0mcgP77LPPuP322xkYGOCnP/0pCxcuxOl0BrsskWumazYiN7AdO3Zw9OhR+vr6SEtL44EHHgh2SSJfi85sRETEOF2zERER4xQ2IiJinMJGRESMU9iIiIhxChsRETFOYSMiIsb9f5FhPIFjo0RxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.countplot(train_df['target'])\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "d5aa5da51ed993b577985d73abe7554a42dcde6e"
   },
   "outputs": [],
   "source": [
    "features = [c for c in train_df.columns if c not in ['ID_code', 'target']]\n",
    "target = train_df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "50977096e5862aae1e81ee95213a6a5795e33a01"
   },
   "source": [
    "# Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "ce2a155cd34809f36d665ce38bb3ec632ca62746"
   },
   "outputs": [],
   "source": [
    "param = {\n",
    "        'bagging_freq': 5,\n",
    "        'bagging_fraction': 0.38,\n",
    "        'boost_from_average':'false',\n",
    "        'boost': 'gbdt',\n",
    "        'feature_fraction': 0.045,\n",
    "        'learning_rate': 0.01,\n",
    "        'max_depth': -1,  \n",
    "        'metric':'auc',\n",
    "        'min_data_in_leaf': 80,\n",
    "        'min_sum_hessian_in_leaf': 10.0,\n",
    "        'num_leaves': 13,\n",
    "        'num_threads': 8,\n",
    "        'tree_learner': 'serial',\n",
    "        'objective': 'binary', \n",
    "        'verbosity': 1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "14dd3fb0df6356857718af9811d446e2e908669d"
   },
   "outputs": [],
   "source": [
    "num_round = 1000000\n",
    "kfold = 15\n",
    "folds = StratifiedKFold(n_splits=12, shuffle=False, random_state=44000)\n",
    "oof = np.zeros(len(train_df))\n",
    "predictions = np.zeros(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Training until validation scores don't improve for 3500 rounds.\n",
      "[1000]\ttraining's auc: 0.900817\tvalid_1's auc: 0.882566\n",
      "[2000]\ttraining's auc: 0.911609\tvalid_1's auc: 0.890527\n",
      "[3000]\ttraining's auc: 0.91882\tvalid_1's auc: 0.895024\n",
      "[4000]\ttraining's auc: 0.924238\tvalid_1's auc: 0.897505\n",
      "[5000]\ttraining's auc: 0.928813\tvalid_1's auc: 0.898706\n",
      "[6000]\ttraining's auc: 0.93292\tvalid_1's auc: 0.899616\n",
      "[7000]\ttraining's auc: 0.9367\tvalid_1's auc: 0.900266\n",
      "[8000]\ttraining's auc: 0.940384\tvalid_1's auc: 0.900674\n",
      "[9000]\ttraining's auc: 0.943791\tvalid_1's auc: 0.901017\n",
      "[10000]\ttraining's auc: 0.947041\tvalid_1's auc: 0.901076\n",
      "[11000]\ttraining's auc: 0.950164\tvalid_1's auc: 0.901232\n",
      "[12000]\ttraining's auc: 0.953156\tvalid_1's auc: 0.901272\n",
      "[13000]\ttraining's auc: 0.956073\tvalid_1's auc: 0.90135\n",
      "[14000]\ttraining's auc: 0.95885\tvalid_1's auc: 0.901287\n",
      "[15000]\ttraining's auc: 0.961534\tvalid_1's auc: 0.901268\n",
      "[16000]\ttraining's auc: 0.964052\tvalid_1's auc: 0.901224\n",
      "Early stopping, best iteration is:\n",
      "[12756]\ttraining's auc: 0.955402\tvalid_1's auc: 0.901408\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 3500 rounds.\n",
      "[1000]\ttraining's auc: 0.900256\tvalid_1's auc: 0.885416\n",
      "[2000]\ttraining's auc: 0.911538\tvalid_1's auc: 0.891264\n",
      "[3000]\ttraining's auc: 0.918731\tvalid_1's auc: 0.894414\n",
      "[4000]\ttraining's auc: 0.924291\tvalid_1's auc: 0.896414\n",
      "[5000]\ttraining's auc: 0.928988\tvalid_1's auc: 0.897533\n",
      "[6000]\ttraining's auc: 0.933177\tvalid_1's auc: 0.898078\n",
      "[7000]\ttraining's auc: 0.937008\tvalid_1's auc: 0.898486\n",
      "[8000]\ttraining's auc: 0.940522\tvalid_1's auc: 0.898611\n",
      "[9000]\ttraining's auc: 0.943887\tvalid_1's auc: 0.89867\n",
      "[10000]\ttraining's auc: 0.947155\tvalid_1's auc: 0.898661\n",
      "[11000]\ttraining's auc: 0.950287\tvalid_1's auc: 0.898605\n",
      "[12000]\ttraining's auc: 0.953258\tvalid_1's auc: 0.898712\n",
      "[13000]\ttraining's auc: 0.956202\tvalid_1's auc: 0.898704\n",
      "[14000]\ttraining's auc: 0.95897\tvalid_1's auc: 0.898296\n",
      "[15000]\ttraining's auc: 0.961588\tvalid_1's auc: 0.898232\n",
      "[16000]\ttraining's auc: 0.964131\tvalid_1's auc: 0.897988\n",
      "Early stopping, best iteration is:\n",
      "[12514]\ttraining's auc: 0.954801\tvalid_1's auc: 0.898806\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 3500 rounds.\n",
      "[1000]\ttraining's auc: 0.901415\tvalid_1's auc: 0.87529\n",
      "[2000]\ttraining's auc: 0.912471\tvalid_1's auc: 0.883087\n",
      "[3000]\ttraining's auc: 0.919554\tvalid_1's auc: 0.886891\n",
      "[4000]\ttraining's auc: 0.924981\tvalid_1's auc: 0.889182\n",
      "[5000]\ttraining's auc: 0.929613\tvalid_1's auc: 0.890392\n",
      "[6000]\ttraining's auc: 0.933645\tvalid_1's auc: 0.891176\n",
      "[7000]\ttraining's auc: 0.937406\tvalid_1's auc: 0.891519\n",
      "[8000]\ttraining's auc: 0.940889\tvalid_1's auc: 0.891789\n",
      "[9000]\ttraining's auc: 0.944278\tvalid_1's auc: 0.892081\n",
      "[10000]\ttraining's auc: 0.947519\tvalid_1's auc: 0.892267\n",
      "[11000]\ttraining's auc: 0.95064\tvalid_1's auc: 0.8921\n",
      "[12000]\ttraining's auc: 0.953583\tvalid_1's auc: 0.891918\n",
      "[13000]\ttraining's auc: 0.956457\tvalid_1's auc: 0.891747\n",
      "Early stopping, best iteration is:\n",
      "[10169]\ttraining's auc: 0.94805\tvalid_1's auc: 0.892322\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 3500 rounds.\n",
      "[1000]\ttraining's auc: 0.899791\tvalid_1's auc: 0.888366\n",
      "[2000]\ttraining's auc: 0.910917\tvalid_1's auc: 0.896961\n",
      "[3000]\ttraining's auc: 0.918088\tvalid_1's auc: 0.90136\n",
      "[4000]\ttraining's auc: 0.923698\tvalid_1's auc: 0.903621\n",
      "[5000]\ttraining's auc: 0.928444\tvalid_1's auc: 0.905134\n",
      "[6000]\ttraining's auc: 0.932528\tvalid_1's auc: 0.905952\n",
      "[7000]\ttraining's auc: 0.936308\tvalid_1's auc: 0.906205\n",
      "[8000]\ttraining's auc: 0.939947\tvalid_1's auc: 0.906233\n",
      "[9000]\ttraining's auc: 0.943373\tvalid_1's auc: 0.906244\n",
      "[10000]\ttraining's auc: 0.946671\tvalid_1's auc: 0.906322\n",
      "[11000]\ttraining's auc: 0.949778\tvalid_1's auc: 0.906205\n",
      "[12000]\ttraining's auc: 0.952738\tvalid_1's auc: 0.906053\n",
      "Early stopping, best iteration is:\n",
      "[8632]\ttraining's auc: 0.942114\tvalid_1's auc: 0.90642\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 3500 rounds.\n",
      "[1000]\ttraining's auc: 0.90075\tvalid_1's auc: 0.875702\n",
      "[2000]\ttraining's auc: 0.911824\tvalid_1's auc: 0.884458\n",
      "[3000]\ttraining's auc: 0.91912\tvalid_1's auc: 0.888545\n",
      "[4000]\ttraining's auc: 0.924696\tvalid_1's auc: 0.890656\n",
      "[5000]\ttraining's auc: 0.929354\tvalid_1's auc: 0.891883\n",
      "[6000]\ttraining's auc: 0.933403\tvalid_1's auc: 0.892828\n",
      "[7000]\ttraining's auc: 0.9372\tvalid_1's auc: 0.893201\n",
      "[8000]\ttraining's auc: 0.940741\tvalid_1's auc: 0.893241\n",
      "[9000]\ttraining's auc: 0.944119\tvalid_1's auc: 0.893156\n",
      "[10000]\ttraining's auc: 0.94732\tvalid_1's auc: 0.893396\n",
      "[11000]\ttraining's auc: 0.950421\tvalid_1's auc: 0.893392\n",
      "[12000]\ttraining's auc: 0.953408\tvalid_1's auc: 0.893238\n",
      "[13000]\ttraining's auc: 0.956283\tvalid_1's auc: 0.893378\n",
      "[14000]\ttraining's auc: 0.95907\tvalid_1's auc: 0.893106\n",
      "Early stopping, best iteration is:\n",
      "[11178]\ttraining's auc: 0.95097\tvalid_1's auc: 0.893512\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 3500 rounds.\n",
      "[1000]\ttraining's auc: 0.900197\tvalid_1's auc: 0.883636\n",
      "[2000]\ttraining's auc: 0.911477\tvalid_1's auc: 0.892045\n",
      "[3000]\ttraining's auc: 0.918575\tvalid_1's auc: 0.89589\n",
      "[4000]\ttraining's auc: 0.924149\tvalid_1's auc: 0.89826\n",
      "[5000]\ttraining's auc: 0.928822\tvalid_1's auc: 0.899173\n",
      "[6000]\ttraining's auc: 0.932959\tvalid_1's auc: 0.899666\n",
      "[7000]\ttraining's auc: 0.936745\tvalid_1's auc: 0.899859\n",
      "[8000]\ttraining's auc: 0.94029\tvalid_1's auc: 0.900148\n",
      "[9000]\ttraining's auc: 0.943651\tvalid_1's auc: 0.900202\n",
      "[10000]\ttraining's auc: 0.946915\tvalid_1's auc: 0.900157\n",
      "[11000]\ttraining's auc: 0.950069\tvalid_1's auc: 0.899822\n",
      "[12000]\ttraining's auc: 0.953071\tvalid_1's auc: 0.899522\n",
      "Early stopping, best iteration is:\n",
      "[9138]\ttraining's auc: 0.94412\tvalid_1's auc: 0.900332\n",
      "Fold 6\n",
      "Training until validation scores don't improve for 3500 rounds.\n",
      "[1000]\ttraining's auc: 0.899851\tvalid_1's auc: 0.886458\n",
      "[2000]\ttraining's auc: 0.911121\tvalid_1's auc: 0.89428\n",
      "[3000]\ttraining's auc: 0.918323\tvalid_1's auc: 0.897865\n",
      "[4000]\ttraining's auc: 0.923958\tvalid_1's auc: 0.899673\n",
      "[5000]\ttraining's auc: 0.928655\tvalid_1's auc: 0.900927\n",
      "[6000]\ttraining's auc: 0.932769\tvalid_1's auc: 0.901527\n",
      "[7000]\ttraining's auc: 0.936577\tvalid_1's auc: 0.901807\n",
      "[8000]\ttraining's auc: 0.94016\tvalid_1's auc: 0.901711\n",
      "[9000]\ttraining's auc: 0.943569\tvalid_1's auc: 0.901773\n",
      "[10000]\ttraining's auc: 0.946832\tvalid_1's auc: 0.901816\n",
      "[11000]\ttraining's auc: 0.949991\tvalid_1's auc: 0.901768\n",
      "Early stopping, best iteration is:\n",
      "[8353]\ttraining's auc: 0.94141\tvalid_1's auc: 0.901887\n",
      "Fold 7\n",
      "Training until validation scores don't improve for 3500 rounds.\n",
      "[1000]\ttraining's auc: 0.899874\tvalid_1's auc: 0.88975\n",
      "[2000]\ttraining's auc: 0.910912\tvalid_1's auc: 0.897039\n",
      "[3000]\ttraining's auc: 0.918153\tvalid_1's auc: 0.900315\n",
      "[4000]\ttraining's auc: 0.923798\tvalid_1's auc: 0.902279\n",
      "[5000]\ttraining's auc: 0.928518\tvalid_1's auc: 0.903105\n",
      "[6000]\ttraining's auc: 0.932656\tvalid_1's auc: 0.903507\n",
      "[7000]\ttraining's auc: 0.936489\tvalid_1's auc: 0.903551\n",
      "[8000]\ttraining's auc: 0.940009\tvalid_1's auc: 0.903715\n",
      "[9000]\ttraining's auc: 0.943423\tvalid_1's auc: 0.903462\n",
      "[10000]\ttraining's auc: 0.946753\tvalid_1's auc: 0.903409\n",
      "[11000]\ttraining's auc: 0.949914\tvalid_1's auc: 0.903482\n",
      "Early stopping, best iteration is:\n",
      "[7990]\ttraining's auc: 0.939972\tvalid_1's auc: 0.903728\n",
      "Fold 8\n",
      "Training until validation scores don't improve for 3500 rounds.\n",
      "[1000]\ttraining's auc: 0.900489\tvalid_1's auc: 0.879809\n",
      "[2000]\ttraining's auc: 0.911488\tvalid_1's auc: 0.888459\n",
      "[3000]\ttraining's auc: 0.918764\tvalid_1's auc: 0.892844\n",
      "[4000]\ttraining's auc: 0.924378\tvalid_1's auc: 0.895152\n",
      "[5000]\ttraining's auc: 0.929051\tvalid_1's auc: 0.896683\n",
      "[6000]\ttraining's auc: 0.933134\tvalid_1's auc: 0.897541\n",
      "[7000]\ttraining's auc: 0.93695\tvalid_1's auc: 0.897953\n",
      "[8000]\ttraining's auc: 0.940491\tvalid_1's auc: 0.898078\n",
      "[9000]\ttraining's auc: 0.943823\tvalid_1's auc: 0.898026\n",
      "[10000]\ttraining's auc: 0.94707\tvalid_1's auc: 0.897996\n",
      "[11000]\ttraining's auc: 0.950186\tvalid_1's auc: 0.898122\n",
      "[12000]\ttraining's auc: 0.953193\tvalid_1's auc: 0.898055\n",
      "[13000]\ttraining's auc: 0.956067\tvalid_1's auc: 0.897968\n",
      "[14000]\ttraining's auc: 0.958843\tvalid_1's auc: 0.897778\n",
      "Early stopping, best iteration is:\n",
      "[11309]\ttraining's auc: 0.951126\tvalid_1's auc: 0.898232\n",
      "Fold 9\n",
      "Training until validation scores don't improve for 3500 rounds.\n",
      "[1000]\ttraining's auc: 0.900041\tvalid_1's auc: 0.887346\n",
      "[2000]\ttraining's auc: 0.911004\tvalid_1's auc: 0.895565\n",
      "[3000]\ttraining's auc: 0.918243\tvalid_1's auc: 0.899618\n",
      "[4000]\ttraining's auc: 0.923783\tvalid_1's auc: 0.901734\n",
      "[5000]\ttraining's auc: 0.928492\tvalid_1's auc: 0.903085\n",
      "[6000]\ttraining's auc: 0.932657\tvalid_1's auc: 0.903423\n",
      "[7000]\ttraining's auc: 0.936453\tvalid_1's auc: 0.903756\n",
      "[8000]\ttraining's auc: 0.940108\tvalid_1's auc: 0.903653\n",
      "[9000]\ttraining's auc: 0.943478\tvalid_1's auc: 0.903792\n",
      "[10000]\ttraining's auc: 0.946744\tvalid_1's auc: 0.903544\n",
      "[11000]\ttraining's auc: 0.949936\tvalid_1's auc: 0.903413\n",
      "[12000]\ttraining's auc: 0.952997\tvalid_1's auc: 0.903179\n",
      "Early stopping, best iteration is:\n",
      "[8554]\ttraining's auc: 0.942012\tvalid_1's auc: 0.903837\n",
      "Fold 10\n",
      "Training until validation scores don't improve for 3500 rounds.\n",
      "[1000]\ttraining's auc: 0.900124\tvalid_1's auc: 0.88927\n",
      "[2000]\ttraining's auc: 0.910722\tvalid_1's auc: 0.89741\n",
      "[3000]\ttraining's auc: 0.918096\tvalid_1's auc: 0.90176\n",
      "[4000]\ttraining's auc: 0.923646\tvalid_1's auc: 0.904299\n",
      "[5000]\ttraining's auc: 0.928214\tvalid_1's auc: 0.905639\n",
      "[6000]\ttraining's auc: 0.932297\tvalid_1's auc: 0.906367\n",
      "[7000]\ttraining's auc: 0.936106\tvalid_1's auc: 0.906973\n",
      "[8000]\ttraining's auc: 0.939707\tvalid_1's auc: 0.907037\n",
      "[9000]\ttraining's auc: 0.943116\tvalid_1's auc: 0.907128\n",
      "[10000]\ttraining's auc: 0.946386\tvalid_1's auc: 0.907089\n",
      "Early stopping, best iteration is:\n",
      "[7346]\ttraining's auc: 0.937356\tvalid_1's auc: 0.907218\n",
      "Fold 11\n",
      "Training until validation scores don't improve for 3500 rounds.\n",
      "[1000]\ttraining's auc: 0.90061\tvalid_1's auc: 0.884898\n",
      "[2000]\ttraining's auc: 0.91161\tvalid_1's auc: 0.891233\n",
      "[3000]\ttraining's auc: 0.918875\tvalid_1's auc: 0.894916\n",
      "[4000]\ttraining's auc: 0.92451\tvalid_1's auc: 0.897127\n",
      "[5000]\ttraining's auc: 0.929113\tvalid_1's auc: 0.898158\n",
      "[6000]\ttraining's auc: 0.933149\tvalid_1's auc: 0.898777\n",
      "[7000]\ttraining's auc: 0.936921\tvalid_1's auc: 0.899275\n",
      "[8000]\ttraining's auc: 0.940461\tvalid_1's auc: 0.899395\n",
      "[9000]\ttraining's auc: 0.943887\tvalid_1's auc: 0.899551\n",
      "[10000]\ttraining's auc: 0.94713\tvalid_1's auc: 0.899557\n",
      "[11000]\ttraining's auc: 0.950278\tvalid_1's auc: 0.899664\n",
      "[12000]\ttraining's auc: 0.953314\tvalid_1's auc: 0.899669\n",
      "[13000]\ttraining's auc: 0.956174\tvalid_1's auc: 0.899513\n",
      "[14000]\ttraining's auc: 0.958916\tvalid_1's auc: 0.899421\n",
      "Early stopping, best iteration is:\n",
      "[10612]\ttraining's auc: 0.949102\tvalid_1's auc: 0.899752\n",
      "CV score: 0.90031 \n"
     ]
    }
   ],
   "source": [
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df.values, target.values)):\n",
    "    print(\"Fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train_df.iloc[trn_idx][features], label=target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_df.iloc[val_idx][features], label=target.iloc[val_idx])\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 3500)\n",
    "    oof[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    predictions += clf.predict(test_df[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "757de0c47f13334bde694a06b3b4eba4c3ae9ad9"
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "b2c5fc1d50c619bc36c1041e63c7a8802ffd8ac0"
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"ID_code\": test_df.ID_code.values})\n",
    "submission[\"target\"] = predictions\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "5fa54f6ffd8cbff04259aa8f56147655a49414bc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>0.100198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>0.204329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>0.171025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>0.219194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>0.041823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code    target\n",
       "0  test_0  0.100198\n",
       "1  test_1  0.204329\n",
       "2  test_2  0.171025\n",
       "3  test_3  0.219194\n",
       "4  test_4  0.041823"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
